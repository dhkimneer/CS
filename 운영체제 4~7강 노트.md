## 4. System Structure & Program Execution 2

<br>

```python
[동기식 입출력과 비동기식 입출력]

1. 동기식 입출력 (synchronous I/O)
 - I/O 요청 후 입출력 작업이 완료된 후에야 제어가 사용자 프로그램에 넘어감
 - 구현 방법 1  # CPU를 가지고 있으면서 기다림
   - I/O가 끝날 때까지 CPU를 낭비시킴
   - 매시점 하나의 I/O만 일어날 수 있음
 - 구현 방법 2  # 일 못할 거 CPU는 다른 프로세스한테 주자! 하는 것
   - I/O가 완료될 때까지 해당 프로그램에게서 CPU를 빼앗음
   - I/O 처리를 기다리는 줄에 그 프로그램을 줄 세움
   - 다른 프로그램에게 CPU를 줌

2. 비동기식 입출력 (asynchronous I/O)
# 요청만 보내놓고 그 프로세서에게 CPU를 바로 넘겨주면, I/O 진행에 상관없이 그 프로세스는 I/O와 무관한 일을 계속 시행
 - I/O가 시작된 후 입출력 작업이 끝나기를 기다리지 않고 제어가 사용자 프로그램에 즉시 넘어감
    
* 두 경우 모두 I/O의 완료는 인터럽트로 알려줌

# (CPU 보유 여부 중요 X) 프로세스가 입출력이 진행되는 동안 아무 것도 수행하지 않다가 입출력이 끝나는 것을 보고 instruction을 수행하면 동기식, 입출력 요청을 하고 나서 바로 instruction을 실행하게 되면 비동기식

# 동기식 입출력에서 결국 I/O 요청을 한 process는 일을 못함


[DMA Controller]

- DMA (Direct Memory Access)
 - 빠른 입출력 장치를 메모리에 가까운 속도로 처리하기 위해 사용
 - CPU의 중재 없이 device controller가 device의 buffer storage의 내용을 메모리에 block 단위로 직접 전송
 - 바이트 단위가 아니라 block 단위로 인터럽트를 발생시킴
    
    
[서로 다른 입출력 명령어]

1. I/O를 수행하는 special instruction에 의해  # 일반적

# Memory 접근하는 instruction이 따로 있고, I/O를 하는 special instruction에 의해 I/O를 하게 만드는 방법

2. Memory Mapped I/O에 의해

# I/O device도 메모리 주소에 연장 주소를 붙여 사용하는 방법


[저장장치 계층 구조]
- Speed / Cost / Volatility

# 위로 갈수록 속도가 빠른 매체를 사용하고 있고, 단위 공간당 가격이 비싸기에 용량이 적다. 또한 위로 갈수록 휘발성이 강하다. (전원이 나가면 내용이 사라짐)

CPU

<Primary(Executable) storage> 
# 휘발성 매체 / CPU에서 직접 접근할 수 있는 매체 (바이트 단위로 접근 가능)
Registers
Cache Memory  # 속도 차이 완충
Main Memory

<Secondary storage> 
# 비휘발성 매체 / sector 단위 접근
Magnetic Disk (ex. 하드 디스크)
Optical Disk
Magnetic Tape

* Caching: copying information into faster storage system
# 빠른 매체로 정보를 읽어들여서 쓰는 것
# 재사용을 목적으로 함.
# 어떤 것을 쫒아낼 것인가? (추후)


[프로그램의 실행 (메모리 load)]

Physical memory
- 프로세스 B (실행파일 B)
- 프로세스 A (실행파일 A)
- kernel # 메모리에 상주

Virtual memory # 각 프로그램마다 독자적으로 가지고 있는 메모리 주소 공간
- 프로세스 B의 address space # code, data, stack
- 프로세스 A의 address space
- Kernel Address space

File system # 전원이 나가도 파일 유지 (하드 디스크)
- 실행파일 B
- 실행파일 A

Swap area 
# 전원이 나가면 의미 없는 data (process 종료 되므로, 하드 디스크)
# 메모리 연장 공간 (물리적 메모리 공간의 한계로 인해서)

//
# 프로그램을 실행시키게 되면 memory address space이 형성이 됨. 0번째부터 시작하는 그 프로그램만의 독자적인 주소 공간이 생김. 주소 공간은 code, data, stack으로 형성됨. code는 CPU에서 실행할 기계어 코드를 담고 있고, Data는 변수 등 자료구조를 담고 있으며 stack은 (코드가 함수 구조로 되어 있으므로) 함수를 호출할 때 data를 쌓아두고 꺼내가는 용도로 쓰임.

# 주소 공간은 물리적 메모리에 다 올려 놓는 것이 아님. 당장 필요한 부분만 올림. 메모리 낭비를 막기 위해서. 이후 사용이 안 되면 물리적 메모리에서 쫒아냄. 한편 당장 필요하지 않은 부분은 디스크에 내려놓음. (Swap area)

# 메모리 주소 변환 (Virtual memory -> Physical Memory)


[커널 주소 공간의 내용]  # OS의 역할이 무엇일까?

1. code

 - 시스템 콜, 인터럽트 처리 코드
 - 자원 관리를 위한 코드
 - 편리한 서비스 제공을 위한 코드

2. data  # OS가 사용하는 자료 구조

 - PCB (Process Control Block)  
   # 현재 실행 중인 프로그램 관리하기 위한 자료구조
 - CPU, Memory, Disk  
   # 종류마다 하드웨어 관리하기 위한 자료구조 존재

3. stack  # 함수를 호출하거나 리턴할 때 이 영역 사용

 - Process A의 커널 스택
 - Process B의 커널 스택


[사용자 프로그램이 사용하는 함수]

# 실행파일 내에 함수들이 포함되어 있다! (ex. 프로세스 A의 address space)

- 함수(function)
 - 사용자 정의 함수
    자신의 프로그램에서 정의한 함수
    
 - 라이브러리 함수
    자신의 프로그램에서 정의하지 않고 갖다 쓴 함수
    자신의 프로그램의 실행 파일에 포함되어 있다.
    
# 커널 함수는 kernel address space code에 들어 있는 함수
    
 - 커널 함수
    운영체제 프로그램의 함수
    커널 함수의 호출 = 시스템 콜  # 프로세스 메모리에서 바로 못 넘어오니까
    
    
[프로그램의 실행]

Program begins
			-> User mode (A의 주소 공간)
    		# 프로그램이 직접 CPU를 잡고 있는 상태
System call
			-> Kernel mode
Return from kernel
			-> User mode (A의 주소 공간)
System call
			-> Kernel mode
Program ends
```

<br>

<br>

<br>

## 5. Process (1)

<br>

```python
[프로세스의 개념]

- Process is a program in execution
# 실행 중인 프로그램을 프로세스라 한다.

- 프로세스의 문맥(context)

 1. CPU 수행 상태를 나타내는 하드웨어 문맥
    - Program Counter
    # 어디를 가리키고 있는가? code 어디까지 수행?
    - 각종 register
    
 2. 프로세스의 주소 공간
    - code, data, stack
    
 3. 프로세스 관련 커널 자료 구조
    - PCB(Process Control Block)
    - Kernel stack
    
    
[프로세스의 상태]

- 프로세스는 상태(state)가 변경되며 수행된다.
 1. Running
    # 사용자 '프로세스'가 커널 모드에서 running하고 있다. (o)
    # '운영체제'가 running하고 있다. (x)
    - CPU를 잡고 instruction을 수행 중인 상태
    
 2. Ready
    - CPU를 기다리는 상태 (메모리 등 다른 조건을 모두 만족하고)
    
 3. Blocked (wait, sleep)  # I/O 일하는 중
    - CPU를 주어도 당장 instruction을 수행할 수 없는 상태
    - Process 자신이 요청한 event(예: I/O)가 즉시 만족되지 않아 이를 기다리는 상태
    - (예) 디스크에서 파일을 읽어와야 하는 경우
    
 4. Suspended (stopped)  # 중기 scheduler 때문에 상태 추가
    - 외부적인 이유로 프로세스의 수행이 정지된 상태
    - 프로세스는 통째로 디스크에 swap out된다.
    - (예) 사용자가 프로그램을 일시정지시킨 경우 (break key)
          시스템이 여러 이유로 프로세스를 잠시 중단시킴  # 중기 sch. 예시
          (메모리에 너무 많은 프로세스가 올라와 있을 때)
    
 * New: 프로세스가 생성 중인 상태
 * Terminated: 수행(execution)이 끝난 상태
 * Blocked: 자신이 요청한 event가 만족되면 Ready
 * Suspended: 외부에서 resume해 주어야 Active
    
    
[프로세스 상태도]


[Process Control Block (PCB)]

- PCB
  - 운영체제가 각 프로세스를 관리하기 위해 프로세스 당 유지하는 정보
  - 다음의 구성요소를 가진다. (구조체로 유지)

   1. OS가 관리상 사용하는 정보
    - Process state, Process ID
    - scheduling information, priority
    
   2. CPU 수행 관련 하드웨어 값
    - Program counter, registers
    # 문맥을 표시하기 위한 정보들
    # CPU에 어떤 register 값들을 넣어서 실행하고 있었는가?
    
   3. 메모리 관련
    - code, data, stack의 위치 정보
    
   4. 파일 관련
    - Open file descriptors...
    
    
[문맥 교환 (context switch)]

- CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정
- CPU가 다른 프로세스에게 넘어갈 때 운영체제는 다음을 수행
 - CPU를 내어주는 프로세스의 상태를 그 프로세스의 PCB에 저장
    # 재개했을 때 중단되었던 그 시점부터 시작할 수 있도록
 - CPU를 새롭게 얻는 프로세스의 상태를 PCB에서 읽어옴


- System call이나 Interrupt 발생 시 반드시 context switch가 일어나는 것은 아니다.
# 프로세스에서 OS로 CPU가 넘어가는 것은 context switch 아님!

(1) User mode A ----------> Kernel mode ----------> User mode A
           Interrupt / System call   문맥교환 없이 user mode 복귀
    
(2) User mode A ----------> Kernel mode ----------> User mode B
           Timer Interrupt /            문맥교환 발생
           I/O 요청 system call
        
 * (1)의 경우에도 CPU 수행 정보 등 context의 일부를 PCB에 save해야 하지만 문맥교환을 하는 (2)의 경우 그 부담이 훨씬 큼 (eg. cache memory flush)

# 문맥 교환 시 보통 캐시 메모리를 다 지워야 함. 그러나 (1)의 경우에서는 그렇게까지 할 필요가 없음.


[프로세스를 스케줄링하기 위한 큐]

- Job queue
 현재 시스템 내에 있는 모든 프로세스의 집합
    
- Ready queue
 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
    
- Device queues
 I/O device의 처리를 기다리는 프로세스의 집합
    
- 프로세스들은 각 큐들을 오가며 수행된다.


[Ready Queue와 다양한 Device Queue]


[프로세스 스케줄링 큐의 모습]


[스케줄러 (Scheduler)]
# 자원별로 스케줄을 정하는 것

1. Long-term Scheduler (장기 스케줄러 or job scheduler)
# 프로세스 생성 - 프로세스 ready 과정 중 admit 과정을 거치는 데, 뭘 admit하냐? 메모리에 올라가는 것을 admit하는 것. long-term scheduler가 그것을 결정하는 것임

 - 시작 프로세스 중 어떤 것들을 ready queue로 보낼지 결정
 - 프로세스에 메모리(및 각종 자원)을 주는 문제
 - degree of Multiprogramming을 제어
    # 메모리에 프로그램이 몇 개 올라가있느냐? 이를 제어
 - time sharing system에는 보통 장기 스케줄러가 없음 (무조건 ready)

2. Short-term Scheduler (단기 스케줄러 or CPU scheduler)

 - 어떤 프로세스를 다음 번에 running 시킬지 결정
 - 프로세스에 CPU를 주는 문제
 - 충분히 빨라야 함 (millisecond 단위)
    
3. Medium-Term Scheduler (중기 스케줄러 or Swapper)
# 현재 사용하는 것, 시작되면 무조건 메모리는 준다. 거기서 뺏는 것

 - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫒아냄
 - 프로세스에게서 memory를 뺏는 문제
 - degree of Multiprogramming을 제어
    
    
[프로세스 상태도]  # 전체 갈무리
```

<br>

<br>

<br>

## 6. Process (2) / 7. Process (3)

<br>

```python
[Thread]
# 프로세스 하나에 CPU 수행 단위를 여러 개 두고 있는 것을 Thread라 부름
# instruction 실행하려면 현재 이 코드의 어느 부분을 실행하고 있는지를 가리키는 program counter가 있어야 한다. 한편 cpu에서 실행되면서 메모리에 register 값들을 setting해 놓고 실행하고 있을 것이다. 각 thread마다 현재 register에 어떤 값을 넣고 프로그램 카운터가 코드 어느 부분을 가리키고 실행하고 있는가를 별도로 유지
# 중간에 함수호출을 하면 그와 관련된 정보를 stack에 쌓아야 하는데, 이것도 별도로 두어야. 이들 이외에는 최대한 thread들마다 공유


- "A thread (or lightweight process) is a basic unit of CPU utilization."  # CPU를 수행하는 단위

- Thread의 구성  # 독립적으로 가짐
  - Program counter
  - Register set
  - Stack space
    
- Thread가 동료 thread와 공유하는 부분(=task)
  - code section
  - data section
  - OS resources
    
- 전통적인 개념의 heavyweight process는 하나의 thread를 가지고 있는 task로 볼 수 있다.
    
# 하나의 프로세스가 주어져 있는데 그 안에 thread가 여러 개 있는 상태

- 다중 스레드로 구성된 태스크 구조에서는 하나의 서브 스레드가 blocked(waiting) 상태인 동안에도 동일한 태스크 내의 다른 스레드가 실행(running)되어 빠른 처리를 할 수 있다.

- 동일한 일을 수행하는 다중 스레드가 협력하여 높은 처리율(throughput)과 성능 향상을 얻을 수 있다.

- 스레드를 사용하면 병렬성을 높일 수 있다.


[Benefits of Threads]

1. Responsiveness # 사용자 입장에서 빠름
  - eg: multi-threaded Web
        if one thread is blocked(network), another thread continues

2. Resource Sharing  # 자원 공유
  - n threads can share binary code, data, resource of the process
    
3. Economy  # 경제성 / ex. thread 간 context switch는 상대적으로 간단
  - creating & CPU switching thread (rather than a process)
  - Solaris의 경우 위 두 가지 overhead가 각각 30배, 5배

4. Utilization of MP(Multi-Processor) Architectures
# CPU가 여러 개일 때 장점 (4번)
  - each thread may be running in parallel on a different processor
    
    
[Implementation of Threads]  # 개념적으로만 알고 있기

- Some are supported by kernel -> Kernel Threads
# 스레드가 여러 개 있다는 사실을 OS 커널이 알고 있음. 하나의 스레드에서 다른 스레드로 CPU가 넘어가는 것도 커널이 CPU 스케줄링하듯 넘겨줌

- Others are supported by library -> User Threads
# 위 사실을 OS가 모름. 유저 프로그램이 스스로 여러 개의 스레드를 관리. (라이브러리 지원을 받아서) 커널이 볼 때는 일반적 프로세스로 보이나 프로세스 본인이 내부에서 CPU 수행 단위를 여러 개 두고 관리하는 방식. 구현 상 제약점이 있을 수 있음
# 사용자 수준에서 스레드를 구현

- Some are real-time threads
```

