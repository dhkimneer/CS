## Ch3. Transport Layer (3)

<br>

#### [3.5. connection-oriented transport: TCP - connection management]

<br>

- 2-way handshaking 시
  - client측에서는 문제가 없다. request를 보내고 짧은 시간 내에 반응이 오므로 server가 alive함을 확인할 수 있기 때문이다.
  - 하지만, server측에서 문제가 발생한다. request를 어느 시점에 보낸 것인지 알 길이 없기에 client가 현재 alive한 상태인지 확신할 수 없다.

<br>

- 3-way handshaking 시

  1. client측에서 syn message를 보낸다.

     - connection을 맺자는 요청을 하기 위해 segment header에 syn bit을 1로 설정한다.
     - sequence number에는 client->server stream에서 사용할 initial sequence number를 적는다.
       - 예시로 sequence number를 x라고 하자.
     - syn message에는 data가 포함되지 않는다.

     <br>

  2. message를 받은 server측에서는 syn ack message를 보낸다.

     - client가 보낸 syn message에 대한 답으로 '네가 원하는 initial sequence number를 써도 좋다.'는 표시를 한다. 이를 ack number field에 한다.
       - (x+1)로 표시하는데, 이유는 다음에 client로부터 (x+1)을 받기를 기대하기 때문이다.
     - 값이 들어가 있음을 표시해주기 위해 ack bit을 1로 설정한다.

     <br>

     - 또한, 서버 측에서도 connection 맺기를 원한다는 것을 표현하기 위해 syn bit을 1로 설정한다.
     - sequence number에는 server->client stream에서 사용할 initial sequence number를 적는다.
       - 예시로 sequence number를 y라고 하자.

     <br>

  3. client측은 이에 ack message로 응답한다.

     - server가 제시한 initial sequence number에 대해 사용해도 좋다는 의미로 ack number field에 (y+1)이라 표시한다.
     - ack number field에 valid한 값을 넣었다는 의미로 ack bit을 1로 설정한다. (ack flag setting)
     - 한편, ack message에는 client로부터 서버로 가는 first application data가 실려나갈 수 있다.
       - sequence number에는 payload에 실은 app data의 first byte 번호인 (x+1)이 적힌다.

<br>

<br>

__TCP, closing a connection__

<br>

- closing은 각 stream(client->server, server->client)에 대해 독립적으로 이루어진다.

  <br>

  - client or server는 자기가 내보내는 stream에 대해 close를 initiate한다.
  - 이는 final segment를 보냄으로 실현된다. FIN bit = 1로 setting되어 나간다.
  - 상대방 측은 ack을 보낸다. 여기서도 보낼 것이 더 이상 없다면 ack segment 내에 마지막 data를 실으면서, FIN bit = 1을 setting해 보낸다.
  - 한편, 양 stream을 closing하는 것은 독립적이기에, 동시에 final segment를 날려도 문제가 없다.

<br>

- Scenario?

  <br>

  1. client측에서 closing이 일어난다. (일반적으로 client측에서 많이 일어남)
  2. app에서 socket을 close하라는 명령이 실행되면 client측 TCP는 server측 TCP에게 final segment를 보낸다. 이 시점 이후로 client측은 더 이상 새로운 data를 보낼 수 없다.
     - 하지만, server는 아직 closing 하지 않았으므로 여전히 서버로부터 data를 받을 수 있다.
  3. server측에서 이에 대한 ack을 보낸다. 이후에도 server는 여전히 data를 보낼 수 있다.
  4. client측이 ack을 받고 나면 stream이 끝난다. 이제 client는 server가 closing하는 것을 기다린다.
  5. server측도 final segment를 만들고, 이제 server도 새로운 data를 보낼 수 없다.
  6. client는 이에 대해 ack을 보낸다.
  7. server측도 closing 상태로 들어간다. 서버는 client를 위한 socket, TCP process 모두를 종료시킨다.

  <br>

  - client측은 ack을 보낸 다음에도(6번), timed wait을 한다.
    - segment가 generate된 이후로 인터넷에서 살아 돌아다닐 수 있는 최대 시간을 segment lifetime이라 한다. 이의 2배 정도의 시간을 기다린다.
    - why?
      - server에서 client가 보낸 ack이 사라졌다고 하자.
      - 서버 측에서는 ack을 못 받았기에 timer가 expire하게 되고, 여전히 final segment를 재전송한다.
      - 서버가 시스템이 허용하는 max 횟수만큼 재전송하고, 서버는 여전히 close하지 못한다.
      - 이렇듯 혹시라도 마지막 final segment에 대해 내보낸 ack이 없어질 상황을 대비해 기다리는 시간을 가진다. 서버가 retransmit하면 대응해주기 위해서이다.

<br>

<br>

<br>

#### [3.6. principles of congestion control]

<br>

- congestion은 source들이 네트워크가 handle할 수 없을 정도로 너무 많은 양의 data를 네트워크로 밀어넣어서 발생한다. 즉, congestion은 네트워크에서 발생하는 문제이다.
- 발생 시 delay가 길어지거나, packet이 drop되는 문제가 발생한다.

<br>

__Cost__

<br>

- retransmission 문제. 불필요한 retransmit이 발생하기도 한다.
  - 실제로 data가 잘 도착하고 ack도 오고 있는데, network 혼잡으로 delay가 길어진다면 timer가 expire하게 되고 불필요한 transmit이 발생한다.
  - 혹은 segment가 목적지까지 잘 왔는데 buffer overflow로 인해 segment를 drop시킨다면 나중에 transmit을 또 해야 한다. 또한 link들을 경유해서 왔는데 goodput으로 연결되지 못하므로 낭비가 발생한다. (upstream transmission capacity 낭비)

<br>

- congestion을 해결하기 위한 approach에는 2종류가 있다.

  <br>

  1. end-to-end congestion control

     - 실제로 congestion이 발생하는 곳은 network 내부(router)임에도 네트워크는 source쪽으로 congestion이므로 rate를 낮춰달라는 메시지를 보내지 않는다.
     - end-system이 결국 loss나 delay를 보고 네트워크의 상태를 감지해 action을 취하게 된다.

     <br>

     - TCP는 이 approach를 택한다.
       - 인터넷 프로토콜인 TCP는 인터넷의 philosophy에 따라 packet을 다음 목적지로 전달하는 기본적인 일을 제외하고는 다른 모든 일을 edge로 떠넘긴다.

  <br>

  2. network assisted congestion control
     - router가 congestion 발생시 edge측에 알린다.
       - congestion이 있는지 없는지만을 알리는 single bit 방식과
       - source(edge)가 어떤 rate로 보내야 한다는 메시지를 첨부하는 explicit rate 알림 방식이 있다.

<br>

<br>

<br>

#### [3.7. TCP congestion control]

<br>

- AIMD control, 즉 Additive Increase Multiplicative Decrease control 방식을 취한다.

- TCP는 대략적으로 매 RTT마다 1mss (maximum segment size)씩 congestion window (cwnd)를 늘려나간다.

  <br>

  - 점진적으로 linear하게 증가하다가 loss 발생 시 cwnd를 많이 줄인다. 
  - 뭐를? cwnd(congestion window)
  - 이런 행태를 반복한다.
  - 이유는 network에 available한 bandwidth를 잡아 사용하기 위해서이다.
    - loss가 발생해 cwnd를 많이 줄이면 congestion은 사라진다.
    - 하지만, 너무 많이 줄여서 혹은 네트워크 상황이 변해서 네트워크에 충분한 bandwidth가 있음에도 불구하고 사용하지 못할 가능성이 있다. 그래서 점진적으로 늘려간다. 그러다 또 loss를 만나면 줄이고.. 이런 행태를 반복한다.
    - 단, loss 발생 시에는 congestion에 빠르게 대응하기 위해 반으로 줄인다.

<br>

- TCP는 in-flight 상태인 byte의 수가 min(cwnd, rwnd)의 값보다 작거나 같도록 pipelining한다.
  - rwnd는 flow control을 다룰 때 나왔었다.
  - in-flight = (lastbytesent - lastbtyeacked) = sent, but not yet acked
- cwnd는 network의 congestion이 다이나믹하게 변하기에 역시 dynamic하게 변한다.
- rwnd는 receiver의 buffer size에 의해 결정되는데, 잠시 동안은 이를 고려하지 않는다.
- 즉, cwnd에 의해 TCP에 내보내는 rate이 결정된다고 하자.

<br>

- 현재 TCP의 congestion window가 cwnd라면, ack을 받지 않은 상태에서 cwnd만큼을 내보낼 수 있다.
- 즉, 한 RTT동안 cwnd개의 byte를 연속적으로 내보낼 수 있다. 더 이상은 내보내면 안 된다.
- 그렇다면 언제 재개 가능한가?
  - ack이 돌아올 때, 그런데 ack이 언제 돌아오나?
    - RTT시간만큼 지나야 돌아온다.
- RTT동안 내보낸 양은 cwnd였다.
- 결국, 현재 congestion window 값이 cwnd인 상황에서는 TCP sending rate가 cwnd / RTT가 된다.

<br>

<br>

__TCP Slow Start__

<br>

- TCP가 어떤 식으로 cwnd 값을 결정하나?

<br>

- connection이 처음 시작했을 때 cwnd 값은 1mss이다.

  - 즉, segment를 하나 내보낼 수 있다.

  <br>

- 이후 TCP는 매 RTT마다 cwnd를 2배로 늘려나간다.

  - 내보낸 segment에 대한 ack이 들어올 때마다 cwnd를 '하나' 증가시켜서 그렇게 만든다.
  - 즉 매 ack마다 cwnd를 하나 증가시키는 것이다.
  - 이렇게 늘려나가는 기간을 slow start phase라고 한다.
  - 이 기간에서는 initial rate가 매우 적으나, exponential하게 커진다.

  <br>

- 한편, 이렇게 늘려나가는 것을 어느 시점에서는 조심해야 한다.

  - cwnd가 충분히 커졌을 때!

    - 충분히 크다는 기준은 네트워크 상황에 따라 다르다.
    - 그렇기에 처음 connection이 시작될 때는 네트워크 상황에 대한 인지가 전혀 없으므로 OS가 default value로서 임계치를 결정한다. 그 이름을 'ssthresh'라고 부른다.

    <br>

  - 결국 cwnd가 ssthresh보다 작은 동안은 slow start를 하고, 같거나 커지게 되면 조심히 늘린다.

    - 조심히 늘린다? congestion avoidance!
    - cwnd를 RTT마다 '하나씩'만 늘린다. 2배가 아니라!
    - 즉, linear하게 늘려 나간다.

  <br>

- 그런데 loss를 경험하면, 기준을 명확히 알게 된다.

  - 예를 들어 cwnd value가 현재 k인데 loss가 발생했다고 하자.
  - 그렇다면 k는 '큰' 값이라는 것이다. 네트워크에 너무 많은 양을 내보내고 있어서 loss가 발생 중
  - loss 경험 시마다 ssthresh를 조정하는데, 현재 cwnd value의 반으로 조정한다.

  <br>

- RTT 한 번 지났을 때 cwnd를 하나만 늘어나기 위해서는,

  - ack을 받을 때마다 mss / cwnd만큼 늘려야 한다.
  - why?
    - 한 RTT 동안 cwnd개의 segment를 내보내므로 들어오는 ack도 cwnd개이다.
    - 그렇기에 ack이 들어올 때마다 cwnd개의 양을 mss / cwnd만큼 늘린다면,
    - 한 RTT가 지났을 때 (cwnd) * (1 + mss / cwnd) = cwnd + mss로 1mss가 늘어나게 된다.

<br>

<br>

__TCP가 loss를 감지하는 방법__

<br>

- timeout (아예 막혀버림, 보내는 segment 없음)
- 3 duplicate acks (중간에 몇몇 loss 발생, 하지만 여전히 보낸 segment가 가고 있음)

<br>

1. TCP Tahoe (예전 버전)

   - 위 2가지 중 어떤 loss를 감지하건 cwnd = 1mss로 줄여버린다.

   <br>

2. TCP Reno (현재 많이 쓰이는 버전)

   - timeout 시에는 Tahoe 버전과 같지만,

   - duplicate acks의 경우에는 cwnd를 현재 value의 반으로 줄인다.

     <br>

     - 그러면 loss 발생 시 ssthresh가 cwnd / 2로 줄어든다. (위에서 설명함)
     - ssthresh를 기준으로 cwnd에 변화를 어떻게 줄 것인가가 결정된다.
       - timeout 시
         - cwnd = 1mss가 되었으므로 rate를 slow start로 exponential하게 증가
       - duplicate 시
         - cwnd가 이전 cwnd의 반으로 줄어든다.
         - 이 때는 ssthresh와 cwnd의 값이 같아지므로 천천히 증가시킨다!

<br>

<br>

<br>

__TCP Performance 측정__

<br>

1. TCP throughput

   <br>

   - 현재 RTT 내에서 cwnd = k라고 하면, throughput은 k / RTT이다.
     - RTT 동안 내보낼 수 있는 cwnd 양이 k이기 때문이다.
   - loss가 발생했을 때 cwnd 크기의 평균치가 w라고 하자.
   - TCP의 cwnd 값은 w / 2 ~ w 사이를 왔다갔다하게 된다.
     - 위에서 loss 발생 시 congestion에 대응하기 위해 반으로 줄인다고 했기 때문
   - 결국 시계열 상 평균적으로 TCP가 한 RTT동안 내보내는 cwnd의 양은 (3 / 4) * w가 될 것이다.
   - 그래서 (3 / 4) * w / RTT 값이 TCP의 throughput이 된다.

   <br>

   - TCP가 cwnd를 둬서 pipelining을 하는 이유는 TCP의 throughput을 위해서이다.

     <br>

     - source - destination을 연결하는 네트워크를 pipe로 보면, pipelining을 하지 않을 시 segment 하나만 나가고 ack이 들어올 때까지 pipe가 비어있게 된다.
     - under utilize를 막기 위해 TCP가 window를 두고 pipe 사정에 맞춰 segment 여러 개를 동시에 내보내는 일을 수행한다.
     - 만약 네트워크가 발전해 pipe가 길어지고 기술이 발달해 bandwidth가 커짐에 따라 pipe가 넓어졌다고 하자. 이 경우 pipe를 잘 이용하려면 결국 window size가 커져야 한다.

   <br>

   - 97년도 논문에 따르면 TCP throughput을 mss, RTT, loss rate의 세 parameter로 표시하고 있다.

     <br>

     - TCP throughput = (1.22 * MSS) / (RTT * sqrt(L))
     - throughput의 좋은 성능을 위해서는 loss rate가 작아야 한다.
     - pipe에 어마한 양의 segment가 차있는데 이 중 하나가 없어지면 TCP는 내보내는 cwnd를 1 혹은 반으로 줄여 RTT만큼 기다리는 상황이 발생한다.
     - 이처럼 loss rate가 크면 pipe가 원래 목적한 throughput을 달성할 수 없다.
       - 위 식에 따르면 예를 들어 10gb / sec의 throughput을 위해 엄청나게 작은 loss rate를 필요로 한다.

     <br>

     - TCP는 현재 매우 인기리에 사용되고 있는 transport protocol이지만, high-speed network에서 TCP가 적절히 동작하게 하기 위해 연구가 이뤄지고 있는 중이다.

<br>

2. TCP fairness

   <br>

   - fair하지 못한다면, TCP가 단위시간 당 많은 양의 일을 하더라도 어떤 connection은 starve하게 된다.
   - bottleneck link의 capacity가 r이라고 할 때, 그 link를 k개의 connection이 지나가고 있다고 하자.
     - 이 경우, r을 k들이 r / k씩 사용할 때 fair하다고 한다.

